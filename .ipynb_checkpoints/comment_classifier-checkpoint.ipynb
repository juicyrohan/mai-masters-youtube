{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b1b115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "#from gensim.models import Word2Vec \n",
    "from itertools import combinations \n",
    "import random \n",
    "import pandas as pd \n",
    "from sklearn.calibration import label_binarize \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, f1_score, roc_auc_score \n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "import numpy as np \n",
    "from transformers import BertTokenizer, BertModel \n",
    "#import shap \n",
    "import matplotlib.pyplot as plt \n",
    "from imblearn.over_sampling import SMOTE \n",
    "import seaborn as sns \n",
    "from ast import literal_eval\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from langdetect import detect\n",
    "import pickle\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from spacy.lang.ru.stop_words import STOP_WORDS as stop_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41dbe5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv('comments_f2v_fts.csv')\n",
    "videos_df = pd.read_csv('vid_fin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f8b22",
   "metadata": {},
   "source": [
    "Отбиарем 1000 размеченных комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21847835",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = comments_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8181b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для подсчета иностранных слов\n",
    "def count_foreign_words(text):\n",
    "    if isinstance(text, str):\n",
    "        foreign_word_count = 0\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            try:\n",
    "                lang = detect(word)\n",
    "                if lang != 'ru':\n",
    "                    foreign_word_count += 1\n",
    "            except LangDetectException:\n",
    "                continue  # Пропускаем слово, если не удалось определить язык\n",
    "        return foreign_word_count\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14e2d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['Foreign_Words'] = comments_df['Processed_Text'].apply(count_foreign_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c31f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели spaCy для русского языка\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "comments_df['Text'] = comments_df['Text'].fillna('').astype(str)\n",
    "# Функция для предобработки текста\n",
    "def preprocess_text(text):\n",
    "    # Обработка NaN значений\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Удаление ссылок и других ненужных символов\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@w+|\\#', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Токенизация и лемматизация\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.lemma_ not in stop_words and token.is_alpha]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Применение предобработки к каждому тексту\n",
    "comments_df['Processed_Text'] = comments_df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Создание корпуса из текстов комментариев\n",
    "corpus = comments_df['Processed_Text'].tolist()\n",
    "\n",
    "# Разделение текста на предложения\n",
    "sentences = [text.split() for text in corpus]\n",
    "\n",
    "# Создание модели Word2Vec\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_comment_vector(comment, model):\n",
    "    words = comment.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "    \n",
    "def extract_additional_features(comment):\n",
    "    length = len(comment)\n",
    "    uppercase_count = sum(1 for c in comment if c.isupper())\n",
    "    punctuation_count = sum(1 for c in comment if c in string.punctuation)\n",
    "    emoji_count = len(re.findall(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0]+', comment))\n",
    "    return np.array([length, uppercase_count, punctuation_count, emoji_count])\n",
    "\n",
    "# Преобразование всех комментариев в векторы и добавление дополнительных признаков\n",
    "def get_combined_vector(comment, model):\n",
    "    word_vector = get_comment_vector(comment, model)\n",
    "    additional_features = extract_additional_features(comment)\n",
    "    combined_vector = np.concatenate((word_vector, additional_features), axis=None)\n",
    "    return combined_vector\n",
    "\n",
    "# Преобразование всех комментариев в векторы\n",
    "comments_df['Vector'] = comments_df['Processed_Text'].apply(lambda x: get_comment_vector(x, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48764e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from gensim.models import FastText\n",
    "from spacy.lang.ru.stop_words import STOP_WORDS as stop_words\n",
    "import fasttext\n",
    "\n",
    "# Load pre-trained FastText model for Russian\n",
    "model_ft = fasttext.load_model('cc.ru.300.bin')\n",
    "\n",
    "# Создание модели FastText (новая модель, обученная на ваших данных)\n",
    "#fasttext_model = FastText(sentences, vector_size=300, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Загрузка предобученной модели FastText\n",
    "#model_path = 'cc.ru.300.bin'  # замените на путь к вашей скачанной модели\n",
    "#pretrained_model = FastText.load_facebook_model(model_path)\n",
    "#pretrained_model = FastTexload_facebook_vectors(model_path)\n",
    "# Дообучение предобученной модели на ваших данных\n",
    "#pretrained_model.build_vocab(sentences, update=True)\n",
    "#pretrained_model.train(sentences, total_examples=pretrained_model.corpus_count, epochs=pretrained_model.epochs)\n",
    "\n",
    "# Функция для получения вектора комментария\n",
    "def get_comment_vector(comment, model):\n",
    "    if comment:\n",
    "        print(len(model.get_sentence_vector(comment)))\n",
    "        return model.get_sentence_vector(comment)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Преобразование всех комментариев в векторы и добавление в DataFrame\n",
    "comments_df['Vector_FT'] = comments_df['Processed_Text'].apply(lambda x: get_comment_vector(x, model_ft))\n",
    "#comments_df['Vector_PT_FT'] = comments_df['Processed_Text'].apply(lambda x: get_comment_vector(x, pretrained_model))\n",
    "\n",
    "# Функция для получения дополнительных признаков\n",
    "def extract_additional_features(comment):\n",
    "    length = len(comment)\n",
    "    uppercase_count = sum(1 for c in comment if c.isupper())\n",
    "    punctuation_count = sum(1 for c in comment if c in string.punctuation)\n",
    "    emoji_count = len(re.findall(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0]+', comment))\n",
    "    return np.array([length, uppercase_count, punctuation_count, emoji_count])\n",
    "\n",
    "\n",
    "# Вывод результатов\n",
    "#print(comments_df[['Text', 'Processed_Text', 'Vector_PT']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf6c1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['Vector_features'] = comments_df['Text'].apply(lambda x: get_combined_vector(preprocess_text(x), word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79280d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_features_label = pd.read_csv('vid_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57cbafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df_fin = comments_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef655cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/4_gxgzyx7131tsyx_ymz0hsm0000gn/T/ipykernel_1945/3002675891.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comments_df_fin['Label'] = comm_features_label['Label']\n"
     ]
    }
   ],
   "source": [
    "comments_df_fin['Label'] = comm_features_label['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3564ab",
   "metadata": {},
   "source": [
    "Теперь построим модель классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0eea31",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b2dd668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.6558157219469972\n",
      "ROC AUC (OvR): 0.6558157219469972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.905\n",
      "F1 Score (Micro): 0.905\n",
      "F1 Score (Macro): 0.31671041119860016\n",
      "ROC AUC (OvO): 0.6053368468977264\n",
      "ROC AUC (OvR): 0.6053368468977264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.00      0.00      0.00        11\n",
      "      normal       0.91      1.00      0.95       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.30      0.33      0.32       200\n",
      "weighted avg       0.82      0.91      0.86       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.915\n",
      "F1 Score (Micro): 0.915\n",
      "F1 Score (Macro): 0.45163572060123786\n",
      "ROC AUC (OvO): 0.6729216508998211\n",
      "ROC AUC (OvR): 0.6729216508998211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.75      0.27      0.40        11\n",
      "      normal       0.92      0.99      0.95       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.56      0.42      0.45       200\n",
      "weighted avg       0.87      0.92      0.89       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.905\n",
      "F1 Score (Micro): 0.905\n",
      "F1 Score (Macro): 0.31671041119860016\n",
      "ROC AUC (OvO): 0.5951785438486697\n",
      "ROC AUC (OvR): 0.5951785438486697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.00      0.00      0.00        11\n",
      "      normal       0.91      1.00      0.95       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.30      0.33      0.32       200\n",
      "weighted avg       0.82      0.91      0.86       200\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab84075",
   "metadata": {},
   "source": [
    "# Word2vec + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4586c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.795\n",
      "F1 Score (Micro): 0.795\n",
      "F1 Score (Macro): 0.39221304567672344\n",
      "ROC AUC (OvO): 0.7197904421437938\n",
      "ROC AUC (OvR): 0.7197904421437938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.22      0.45      0.29        11\n",
      "      normal       0.92      0.85      0.88       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.38      0.44      0.39       200\n",
      "weighted avg       0.84      0.80      0.81       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.275\n",
      "F1 Score (Micro): 0.275\n",
      "F1 Score (Macro): 0.23045065220807792\n",
      "ROC AUC (OvO): 0.6539688589267714\n",
      "ROC AUC (OvR): 0.6539688589267714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.08      0.64      0.14        11\n",
      "      normal       0.95      0.23      0.37       181\n",
      "       troll       0.10      0.88      0.19         8\n",
      "\n",
      "    accuracy                           0.28       200\n",
      "   macro avg       0.38      0.58      0.23       200\n",
      "weighted avg       0.87      0.28      0.35       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.7\n",
      "F1 Score (Micro): 0.7\n",
      "F1 Score (Macro): 0.39368849349397\n",
      "ROC AUC (OvO): 0.7099268316386831\n",
      "ROC AUC (OvR): 0.7099268316386831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.17      0.45      0.24        11\n",
      "      normal       0.92      0.73      0.82       181\n",
      "       troll       0.08      0.25      0.12         8\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.39      0.48      0.39       200\n",
      "weighted avg       0.84      0.70      0.76       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.16\n",
      "F1 Score (Micro): 0.16\n",
      "F1 Score (Macro): 0.14239546893220056\n",
      "ROC AUC (OvO): 0.6031329591437076\n",
      "ROC AUC (OvR): 0.6031329591437076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.05      0.36      0.09        11\n",
      "      normal       0.95      0.12      0.21       181\n",
      "       troll       0.07      0.88      0.13         8\n",
      "\n",
      "    accuracy                           0.16       200\n",
      "   macro avg       0.36      0.45      0.14       200\n",
      "weighted avg       0.87      0.16      0.20       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ed883",
   "metadata": {},
   "source": [
    "# Standardized Word2vec + SMOTE + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf25a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.79\n",
      "F1 Score (Micro): 0.79\n",
      "F1 Score (Macro): 0.3883415435139573\n",
      "ROC AUC (OvO): 0.7183169549747657\n",
      "ROC AUC (OvR): 0.7183169549747657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.21      0.45      0.29        11\n",
      "      normal       0.92      0.85      0.88       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.37      0.43      0.39       200\n",
      "weighted avg       0.84      0.79      0.81       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.52\n",
      "F1 Score (Micro): 0.52\n",
      "F1 Score (Macro): 0.34145880574452003\n",
      "ROC AUC (OvO): 0.6687594327671461\n",
      "ROC AUC (OvR): 0.6687594327671461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.11      0.64      0.19        11\n",
      "      normal       0.95      0.51      0.67       181\n",
      "       troll       0.10      0.50      0.16         8\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.39      0.55      0.34       200\n",
      "weighted avg       0.87      0.52      0.62       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.705\n",
      "F1 Score (Micro): 0.705\n",
      "F1 Score (Macro): 0.3961581014892717\n",
      "ROC AUC (OvO): 0.7236431406214138\n",
      "ROC AUC (OvR): 0.7236431406214138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.17      0.45      0.24        11\n",
      "      normal       0.92      0.74      0.82       181\n",
      "       troll       0.08      0.25      0.12         8\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.39      0.48      0.40       200\n",
      "weighted avg       0.84      0.70      0.76       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.335\n",
      "F1 Score (Micro): 0.335\n",
      "F1 Score (Macro): 0.2528403168647071\n",
      "ROC AUC (OvO): 0.7302518815320805\n",
      "ROC AUC (OvR): 0.7302518815320805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.09      0.55      0.15        11\n",
      "      normal       0.93      0.30      0.46       181\n",
      "       troll       0.08      0.75      0.15         8\n",
      "\n",
      "    accuracy                           0.34       200\n",
      "   macro avg       0.37      0.53      0.25       200\n",
      "weighted avg       0.85      0.34      0.43       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Стандартизация признаков\n",
    "scaler = StandardScaler()\n",
    "X_train_smote = scaler.fit_transform(X_train_smote)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025189b",
   "metadata": {},
   "source": [
    "# Word2vec + SMOTE + Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b37886de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.64\n",
      "F1 Score (Micro): 0.64\n",
      "F1 Score (Macro): 0.36143237605691514\n",
      "ROC AUC (OvO): 0.686852599321098\n",
      "ROC AUC (OvR): 0.686852599321098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.14      0.45      0.21        11\n",
      "      normal       0.91      0.67      0.77       181\n",
      "       troll       0.07      0.25      0.11         8\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.37      0.46      0.36       200\n",
      "weighted avg       0.83      0.64      0.71       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.26\n",
      "F1 Score (Micro): 0.26\n",
      "F1 Score (Macro): 0.22210820446114565\n",
      "ROC AUC (OvO): 0.6332451479631573\n",
      "ROC AUC (OvR): 0.6332451479631573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.55      0.11        11\n",
      "      normal       0.95      0.22      0.35       181\n",
      "       troll       0.12      0.88      0.21         8\n",
      "\n",
      "    accuracy                           0.26       200\n",
      "   macro avg       0.38      0.55      0.22       200\n",
      "weighted avg       0.87      0.26      0.33       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.71\n",
      "F1 Score (Micro): 0.7100000000000001\n",
      "F1 Score (Macro): 0.4545147588662551\n",
      "ROC AUC (OvO): 0.727754744698866\n",
      "ROC AUC (OvR): 0.727754744698866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.19      0.55      0.28        11\n",
      "      normal       0.95      0.72      0.82       181\n",
      "       troll       0.17      0.62      0.26         8\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.43      0.63      0.45       200\n",
      "weighted avg       0.88      0.71      0.77       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.275\n",
      "F1 Score (Micro): 0.275\n",
      "F1 Score (Macro): 0.21466772343965324\n",
      "ROC AUC (OvO): 0.6278132876662609\n",
      "ROC AUC (OvR): 0.6278132876662609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.45      0.11        11\n",
      "      normal       0.94      0.24      0.39       181\n",
      "       troll       0.08      0.75      0.15         8\n",
      "\n",
      "    accuracy                           0.28       200\n",
      "   macro avg       0.36      0.48      0.21       200\n",
      "weighted avg       0.85      0.28      0.36       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63a70a",
   "metadata": {},
   "source": [
    "# Word2vec + SMOTE + Standardized Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d87ec2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.775\n",
      "F1 Score (Micro): 0.775\n",
      "F1 Score (Macro): 0.44004121423476267\n",
      "ROC AUC (OvO): 0.6904555357813633\n",
      "ROC AUC (OvR): 0.6904555357813633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.19      0.45      0.27        11\n",
      "      normal       0.93      0.82      0.87       181\n",
      "       troll       0.14      0.25      0.18         8\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.42      0.51      0.44       200\n",
      "weighted avg       0.85      0.78      0.81       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.25\n",
      "F1 Score (Micro): 0.25\n",
      "F1 Score (Macro): 0.2155307994757536\n",
      "ROC AUC (OvO): 0.6245253183651656\n",
      "ROC AUC (OvR): 0.6245253183651656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.55      0.11        11\n",
      "      normal       1.00      0.20      0.34       181\n",
      "       troll       0.11      0.88      0.20         8\n",
      "\n",
      "    accuracy                           0.25       200\n",
      "   macro avg       0.39      0.54      0.22       200\n",
      "weighted avg       0.91      0.25      0.32       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.74\n",
      "F1 Score (Micro): 0.74\n",
      "F1 Score (Macro): 0.4467257033746395\n",
      "ROC AUC (OvO): 0.7253627195446145\n",
      "ROC AUC (OvR): 0.7253627195446145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.21      0.55      0.31        11\n",
      "      normal       0.94      0.77      0.84       181\n",
      "       troll       0.12      0.38      0.19         8\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.43      0.56      0.45       200\n",
      "weighted avg       0.87      0.74      0.79       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.265\n",
      "F1 Score (Micro): 0.265\n",
      "F1 Score (Macro): 0.21918162953816603\n",
      "ROC AUC (OvO): 0.6513717399412354\n",
      "ROC AUC (OvR): 0.6513717399412354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.03      0.27      0.05        11\n",
      "      normal       0.91      0.24      0.38       181\n",
      "       troll       0.13      0.88      0.23         8\n",
      "\n",
      "    accuracy                           0.27       200\n",
      "   macro avg       0.36      0.46      0.22       200\n",
      "weighted avg       0.83      0.27      0.35       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Выделение последних четырех признаков для стандартизации\n",
    "X_additional = X[:, -4:]\n",
    "\n",
    "# Стандартизация последних четырех признаков\n",
    "scaler = StandardScaler()\n",
    "X_additional_scaled = scaler.fit_transform(X_additional)\n",
    "\n",
    "# Объединение стандартизированных признаков с остальными\n",
    "X_combined = np.hstack((X[:, :-4], X_additional_scaled))\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d7be4",
   "metadata": {},
   "source": [
    "# PCA (Word2vec) + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21498af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.865\n",
      "F1 Score (Micro): 0.865\n",
      "F1 Score (Macro): 0.5404007756948933\n",
      "ROC AUC (OvO): 0.8290817200955655\n",
      "ROC AUC (OvR): 0.8290817200955655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.40      0.55      0.46        11\n",
      "      normal       0.94      0.91      0.92       181\n",
      "       troll       0.22      0.25      0.24         8\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.52      0.57      0.54       200\n",
      "weighted avg       0.88      0.86      0.87       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.29\n",
      "F1 Score (Micro): 0.29\n",
      "F1 Score (Macro): 0.23942284294707203\n",
      "ROC AUC (OvO): 0.6525923527472473\n",
      "ROC AUC (OvR): 0.6525923527472473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.08      0.64      0.14        11\n",
      "      normal       0.96      0.24      0.39       181\n",
      "       troll       0.11      0.88      0.19         8\n",
      "\n",
      "    accuracy                           0.29       200\n",
      "   macro avg       0.38      0.58      0.24       200\n",
      "weighted avg       0.87      0.29      0.37       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.81\n",
      "F1 Score (Micro): 0.81\n",
      "F1 Score (Macro): 0.5358974358974359\n",
      "ROC AUC (OvO): 0.8503245989445194\n",
      "ROC AUC (OvR): 0.8503245989445194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.30      0.64      0.41        11\n",
      "      normal       0.95      0.83      0.89       181\n",
      "       troll       0.22      0.50      0.31         8\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.49      0.66      0.54       200\n",
      "weighted avg       0.89      0.81      0.84       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.37\n",
      "F1 Score (Micro): 0.37\n",
      "F1 Score (Macro): 0.2389877864608602\n",
      "ROC AUC (OvO): 0.5962456855374038\n",
      "ROC AUC (OvR): 0.5962456855374038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.03      0.18      0.06        11\n",
      "      normal       0.91      0.37      0.53       181\n",
      "       troll       0.08      0.62      0.14         8\n",
      "\n",
      "    accuracy                           0.37       200\n",
      "   macro avg       0.34      0.39      0.24       200\n",
      "weighted avg       0.82      0.37      0.48       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Применение PCA для уменьшения размерности векторов Word2Vec\n",
    "pca = PCA(n_components=25, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42, kernel='rbf')\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8d53727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA (Standardized Word2vec) + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce36387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd753adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df_fin['Vector_features'][0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5aebcd",
   "metadata": {},
   "source": [
    "# PCA (Word2vec) + SMOTE + Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0c46a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4b238ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.875\n",
      "F1 Score (Micro): 0.875\n",
      "F1 Score (Macro): 0.5481664517977367\n",
      "ROC AUC (OvO): 0.7794330055545049\n",
      "ROC AUC (OvR): 0.7794330055545049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.40      0.55      0.46        11\n",
      "      normal       0.94      0.92      0.93       181\n",
      "       troll       0.25      0.25      0.25         8\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.53      0.57      0.55       200\n",
      "weighted avg       0.89      0.88      0.88       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.265\n",
      "F1 Score (Micro): 0.265\n",
      "F1 Score (Macro): 0.22559684253011336\n",
      "ROC AUC (OvO): 0.634764792540074\n",
      "ROC AUC (OvR): 0.634764792540074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.55      0.11        11\n",
      "      normal       0.95      0.22      0.36       181\n",
      "       troll       0.12      0.88      0.21         8\n",
      "\n",
      "    accuracy                           0.27       200\n",
      "   macro avg       0.38      0.55      0.23       200\n",
      "weighted avg       0.87      0.27      0.34       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.81\n",
      "F1 Score (Micro): 0.81\n",
      "F1 Score (Macro): 0.4790051679586563\n",
      "ROC AUC (OvO): 0.8262149773382372\n",
      "ROC AUC (OvR): 0.8262149773382372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.29      0.55      0.37        11\n",
      "      normal       0.94      0.85      0.90       181\n",
      "       troll       0.12      0.25      0.17         8\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.45      0.55      0.48       200\n",
      "weighted avg       0.88      0.81      0.84       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.275\n",
      "F1 Score (Micro): 0.275\n",
      "F1 Score (Macro): 0.21466772343965324\n",
      "ROC AUC (OvO): 0.627779766357175\n",
      "ROC AUC (OvR): 0.627779766357175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.45      0.11        11\n",
      "      normal       0.94      0.24      0.39       181\n",
      "       troll       0.08      0.75      0.15         8\n",
      "\n",
      "    accuracy                           0.28       200\n",
      "   macro avg       0.36      0.48      0.21       200\n",
      "weighted avg       0.85      0.28      0.36       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Выделение последних четырех признаков для стандартизации\n",
    "X_additional = X[:, -4:]\n",
    "\n",
    "# Применение PCA для уменьшения размерности векторов Word2Vec\n",
    "pca = PCA(n_components=25, random_state=42)\n",
    "X_pca = pca.fit_transform(X[:, :-4])\n",
    "\n",
    "# Стандартизация последних четырех признаков\n",
    "#scaler = StandardScaler()\n",
    "#X_additional_scaled = scaler.fit_transform(X_additional)\n",
    "\n",
    "# Объединение стандартизированных признаков с остальными\n",
    "X_combined = np.hstack((X_pca, X_additional))\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d50db8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Meta Model:\n",
      "Accuracy: 0.2830188679245283\n",
      "F1 Score (Micro): 0.2830188679245283\n",
      "F1 Score (Macro): 0.23836657169990505\n",
      "ROC AUC (OvO): 0.44903846153846155\n",
      "ROC AUC (OvR): 0.44903846153846155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.10      0.40      0.15         5\n",
      "      normal       0.79      0.28      0.41        40\n",
      "       troll       0.11      0.25      0.15         8\n",
      "\n",
      "    accuracy                           0.28        53\n",
      "   macro avg       0.33      0.31      0.24        53\n",
      "weighted avg       0.62      0.28      0.35        53\n",
      "\n",
      "\n",
      "Gradient Boosting Meta Model:\n",
      "Accuracy: 0.6981132075471698\n",
      "F1 Score (Micro): 0.6981132075471698\n",
      "F1 Score (Macro): 0.4102067183462533\n",
      "ROC AUC (OvO): 0.491951566951567\n",
      "ROC AUC (OvR): 0.491951566951567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.33      0.20      0.25         5\n",
      "      normal       0.76      0.88      0.81        40\n",
      "       troll       0.25      0.12      0.17         8\n",
      "\n",
      "    accuracy                           0.70        53\n",
      "   macro avg       0.45      0.40      0.41        53\n",
      "weighted avg       0.64      0.70      0.66        53\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "X_word2vec = X[:, :-4]\n",
    "# Здесь можно добавить свои признаки\n",
    "# Выделение последних четырех признаков для стандартизации\n",
    "X_additional = X[:, -4:]\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Стандартизация данных\n",
    "#scaler_word2vec = StandardScaler()\n",
    "#X_word2vec = scaler_word2vec.fit_transform(X_word2vec)\n",
    "\n",
    "scaler_additional = StandardScaler()\n",
    "X_additional = scaler_additional.fit_transform(X_additional)\n",
    "\n",
    "n_components = 25\n",
    "# Применение PCA с выбранным числом компонентов\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_word2vec_pca = pca.fit_transform(X_word2vec)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train_word2vec, X_test_word2vec, y_train, y_test = train_test_split(X_word2vec_pca, y, test_size=0.2, random_state=42)\n",
    "X_train_additional, X_test_additional, _, _ = train_test_split(X_additional, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_word2vec_smote, y_train_smote = smote.fit_resample(X_train_word2vec, y_train)\n",
    "X_train_additional_smote, _ = smote.fit_resample(X_train_additional, y_train)\n",
    "\n",
    "# Создание моделей для каждой группы признаков\n",
    "rf_model_word2vec = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model_word2vec = LogisticRegression(max_iter=1000, random_state=42)\n",
    "gb_model_word2vec = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model_word2vec = SVC(probability=True, random_state=42)\n",
    "\n",
    "rf_model_additional = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model_additional = LogisticRegression(max_iter=1000, random_state=42)\n",
    "gb_model_additional = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model_additional = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Создание словаря базовых моделей\n",
    "base_models_word2vec = {\n",
    "    \"Random Forest Word2Vec\": rf_model_word2vec,\n",
    "    #\"Logistic Regression Word2Vec\": lr_model_word2vec,\n",
    "    \"Gradient Boosting Word2Vec\": gb_model_word2vec,\n",
    "    #\"SVC Word2Vec\": svc_model_word2vec\n",
    "}\n",
    "\n",
    "base_models_additional = {\n",
    "    #\"Random Forest Additional\": rf_model_additional,\n",
    "    #\"Logistic Regression Additional\": lr_model_additional,\n",
    "    #\"Gradient Boosting Additional\": gb_model_additional,\n",
    "    \"SVC Additional\": svc_model_additional\n",
    "}\n",
    "\n",
    "# Получение метапризнаков через кросс-валидацию\n",
    "def get_meta_features(model_dict, X, y):\n",
    "    meta_features = np.zeros((X.shape[0], len(model_dict)))\n",
    "    for i, (name, model) in enumerate(model_dict.items()):\n",
    "        meta_features[:, i] = cross_val_predict(model, X, y, cv=5, method='predict_proba')[:, 1]\n",
    "    return meta_features\n",
    "\n",
    "meta_features_word2vec = get_meta_features(base_models_word2vec, X_word2vec_pca, y)\n",
    "meta_features_additional = get_meta_features(base_models_additional, X_additional, y)\n",
    "\n",
    "# Объединение метапризнаков\n",
    "meta_features_combined = np.hstack([meta_features_word2vec, meta_features_additional])\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки для метамодели\n",
    "X_train_meta, X_test_meta, y_train_meta, y_test_meta = train_test_split(meta_features_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке метамодели\n",
    "X_train_meta_smote, y_train_meta_smote = smote.fit_resample(X_train_meta, y_train_meta)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Обучение Logistic Regression как метамодели\n",
    "lr_meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_meta_model.fit(X_train_meta_smote, y_train_meta_smote)\n",
    "\n",
    "# Обучение Gradient Boosting как метамодели\n",
    "gb_meta_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_meta_model.fit(X_train_meta, y_train_meta)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка Logistic Regression метамодели\n",
    "y_pred_lr_meta = lr_meta_model.predict(X_test_meta)\n",
    "y_proba_lr_meta = lr_meta_model.predict_proba(X_test_meta)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка Gradient Boosting метамодели\n",
    "y_pred_gb_meta = gb_meta_model.predict(X_test_meta)\n",
    "y_proba_gb_meta = gb_meta_model.predict_proba(X_test_meta)\n",
    "\n",
    "# Функция для оценки модели\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Оценка метамоделей\n",
    "evaluate_model(y_test_meta, y_pred_lr_meta, y_proba_lr_meta, \"Logistic Regression Meta Model\")\n",
    "evaluate_model(y_test_meta, y_pred_gb_meta, y_proba_gb_meta, \"Gradient Boosting Meta Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d5bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
