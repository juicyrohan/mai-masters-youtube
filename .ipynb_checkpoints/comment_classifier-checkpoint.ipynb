{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b1b115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "#from gensim.models import Word2Vec \n",
    "from itertools import combinations \n",
    "import random \n",
    "import pandas as pd \n",
    "from sklearn.calibration import label_binarize \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, f1_score, roc_auc_score \n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "import numpy as np \n",
    "from transformers import BertTokenizer, BertModel \n",
    "#import shap \n",
    "import matplotlib.pyplot as plt \n",
    "from imblearn.over_sampling import SMOTE \n",
    "import seaborn as sns \n",
    "from ast import literal_eval\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from langdetect import detect\n",
    "import pickle\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from spacy.lang.ru.stop_words import STOP_WORDS as stop_words\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41dbe5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv('comments_f2v_fts.csv')\n",
    "videos_df = pd.read_csv('vid_fin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f8cf1",
   "metadata": {},
   "source": [
    "Отбиарем 1000 размеченных комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21847835",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = comments_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8181b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для подсчета иностранных слов\n",
    "def count_foreign_words(text):\n",
    "    if isinstance(text, str):\n",
    "        foreign_word_count = 0\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            try:\n",
    "                lang = detect(word)\n",
    "                if lang != 'ru':\n",
    "                    foreign_word_count += 1\n",
    "            except LangDetectException:\n",
    "                continue  # Пропускаем слово, если не удалось определить язык\n",
    "        return foreign_word_count\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e2d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['Foreign_Words'] = comments_df['Processed_Text'].apply(count_foreign_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c31f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели spaCy для русского языка\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "comments_df['Text'] = comments_df['Text'].fillna('').astype(str)\n",
    "# Функция для предобработки текста\n",
    "def preprocess_text(text):\n",
    "    # Обработка NaN значений\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Удаление ссылок и других ненужных символов\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@w+|\\#', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Токенизация и лемматизация\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.lemma_ not in stop_words and token.is_alpha]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Применение предобработки к каждому тексту\n",
    "comments_df['Processed_Text'] = comments_df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Создание корпуса из текстов комментариев\n",
    "corpus = comments_df['Processed_Text'].tolist()\n",
    "\n",
    "# Разделение текста на предложения\n",
    "sentences = [text.split() for text in corpus]\n",
    "\n",
    "# Создание модели Word2Vec\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_comment_vector(comment, model):\n",
    "    words = comment.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "    \n",
    "def extract_additional_features(comment):\n",
    "    length = len(comment)\n",
    "    uppercase_count = sum(1 for c in comment if c.isupper())\n",
    "    punctuation_count = sum(1 for c in comment if c in string.punctuation)\n",
    "    emoji_count = len(re.findall(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0]+', comment))\n",
    "    return np.array([length, uppercase_count, punctuation_count, emoji_count])\n",
    "\n",
    "# Преобразование всех комментариев в векторы и добавление дополнительных признаков\n",
    "def get_combined_vector(comment, model):\n",
    "    word_vector = get_comment_vector(comment, model)\n",
    "    additional_features = extract_additional_features(comment)\n",
    "    combined_vector = np.concatenate((word_vector, additional_features), axis=None)\n",
    "    return combined_vector\n",
    "\n",
    "# Преобразование всех комментариев в векторы\n",
    "comments_df['Vector'] = comments_df['Processed_Text'].apply(lambda x: get_comment_vector(x, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6c1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['Vector_features'] = comments_df['Text'].apply(lambda x: get_combined_vector(preprocess_text(x), word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79280d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_features_label = pd.read_csv('vid_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cbafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df_fin = comments_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef655cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df_fin['Label'] = comm_features_label['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "674a183a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Series name: Vector_features\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "1000 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "comments_df_fin['Vector_features'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd5e9f",
   "metadata": {},
   "source": [
    "Теперь построим модель классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0eea31",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2dd668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.4269255603687511\n",
      "ROC AUC (OvR): 0.4269255603687511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.905\n",
      "F1 Score (Micro): 0.905\n",
      "F1 Score (Macro): 0.31671041119860016\n",
      "ROC AUC (OvO): 0.6244456579965479\n",
      "ROC AUC (OvR): 0.6244456579965479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.00      0.00      0.00        11\n",
      "      normal       0.91      1.00      0.95       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.30      0.33      0.32       200\n",
      "weighted avg       0.82      0.91      0.86       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.5455621705396426\n",
      "ROC AUC (OvR): 0.5455621705396426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.5445465355559511\n",
      "ROC AUC (OvR): 0.5445465355559511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.4269255603687511\n",
      "ROC AUC (OvR): 0.4269255603687511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.905\n",
      "F1 Score (Micro): 0.905\n",
      "F1 Score (Macro): 0.31671041119860016\n",
      "ROC AUC (OvO): 0.6244456579965479\n",
      "ROC AUC (OvR): 0.6244456579965479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.00      0.00      0.00        11\n",
      "      normal       0.91      1.00      0.95       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.30      0.33      0.32       200\n",
      "weighted avg       0.82      0.91      0.86       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.5455621705396426\n",
      "ROC AUC (OvR): 0.5455621705396426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.5445465355559511\n",
      "ROC AUC (OvR): 0.5445465355559511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)\n",
    "    \n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab84075",
   "metadata": {},
   "source": [
    "# Word2vec + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4586c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.89\n",
      "F1 Score (Micro): 0.89\n",
      "F1 Score (Macro): 0.472135955831608\n",
      "ROC AUC (OvO): 0.6221793962111445\n",
      "ROC AUC (OvR): 0.6221793962111445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.50      0.45      0.48        11\n",
      "      normal       0.93      0.96      0.94       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.48      0.47      0.47       200\n",
      "weighted avg       0.86      0.89      0.88       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.415\n",
      "F1 Score (Micro): 0.415\n",
      "F1 Score (Macro): 0.27315172018121747\n",
      "ROC AUC (OvO): 0.5743278209173773\n",
      "ROC AUC (OvR): 0.5743278209173773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.08      0.55      0.14        11\n",
      "      normal       0.95      0.41      0.57       181\n",
      "       troll       0.06      0.38      0.10         8\n",
      "\n",
      "    accuracy                           0.41       200\n",
      "   macro avg       0.36      0.44      0.27       200\n",
      "weighted avg       0.87      0.41      0.53       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.865\n",
      "F1 Score (Micro): 0.865\n",
      "F1 Score (Macro): 0.46090741670852164\n",
      "ROC AUC (OvO): 0.6230036383499721\n",
      "ROC AUC (OvR): 0.6230036383499721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.45      0.45      0.45        11\n",
      "      normal       0.93      0.93      0.93       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.46      0.46      0.46       200\n",
      "weighted avg       0.86      0.86      0.86       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.825\n",
      "F1 Score (Micro): 0.825\n",
      "F1 Score (Macro): 0.43532763532763535\n",
      "ROC AUC (OvO): 0.7140574294976995\n",
      "ROC AUC (OvR): 0.7140574294976995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.32      0.55      0.40        11\n",
      "      normal       0.94      0.88      0.91       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.42      0.47      0.44       200\n",
      "weighted avg       0.86      0.82      0.84       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ed883",
   "metadata": {},
   "source": [
    "# Standardized Word2vec + SMOTE + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf25a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/00/4_gxgzyx7131tsyx_ymz0hsm0000gn/T/ipykernel_6970/515049937.py\", line 12, in <module>\n",
      "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/imblearn/base.py\", line 203, in fit_resample\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/imblearn/base.py\", line 88, in fit_resample\n",
      "    X : {array-like, dataframe, sparse matrix} of shape \\\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py\", line 355, in _fit_resample\n",
      "    random_state=random_state,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py\", line 824, in kneighbors\n",
      "    else:\n",
      "          \n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 277, in compute\n",
      "    if X.dtype == Y.dtype == np.float64:\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 95, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 135, in threadpool_limits\n",
      "    the_min = the_min.toarray().ravel()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 129, in _get_threadpool_controller\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 818, in __init__\n",
      "    self._load_libraries()\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 970, in _load_libraries\n",
      "    self._find_libraries_with_dyld()\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 1040, in _find_libraries_with_dyld\n",
      "    self._make_controller_from_path(filepath)\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 1175, in _make_controller_from_path\n",
      "    lib_controller = controller_class(\n",
      "                     ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 114, in __init__\n",
      "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: image not already loaded\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Стандартизация признаков\n",
    "scaler = StandardScaler()\n",
    "X_train_smote = scaler.fit_transform(X_train_smote)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025189b",
   "metadata": {},
   "source": [
    "# Word2vec + SMOTE + Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b37886de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.64\n",
      "F1 Score (Micro): 0.64\n",
      "F1 Score (Macro): 0.36143237605691514\n",
      "ROC AUC (OvO): 0.686852599321098\n",
      "ROC AUC (OvR): 0.686852599321098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.14      0.45      0.21        11\n",
      "      normal       0.91      0.67      0.77       181\n",
      "       troll       0.07      0.25      0.11         8\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.37      0.46      0.36       200\n",
      "weighted avg       0.83      0.64      0.71       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.26\n",
      "F1 Score (Micro): 0.26\n",
      "F1 Score (Macro): 0.22210820446114565\n",
      "ROC AUC (OvO): 0.6332451479631573\n",
      "ROC AUC (OvR): 0.6332451479631573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.55      0.11        11\n",
      "      normal       0.95      0.22      0.35       181\n",
      "       troll       0.12      0.88      0.21         8\n",
      "\n",
      "    accuracy                           0.26       200\n",
      "   macro avg       0.38      0.55      0.22       200\n",
      "weighted avg       0.87      0.26      0.33       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.71\n",
      "F1 Score (Micro): 0.7100000000000001\n",
      "F1 Score (Macro): 0.4545147588662551\n",
      "ROC AUC (OvO): 0.727754744698866\n",
      "ROC AUC (OvR): 0.727754744698866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.19      0.55      0.28        11\n",
      "      normal       0.95      0.72      0.82       181\n",
      "       troll       0.17      0.62      0.26         8\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.43      0.63      0.45       200\n",
      "weighted avg       0.88      0.71      0.77       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.275\n",
      "F1 Score (Micro): 0.275\n",
      "F1 Score (Macro): 0.21466772343965324\n",
      "ROC AUC (OvO): 0.6278132876662609\n",
      "ROC AUC (OvR): 0.6278132876662609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.45      0.11        11\n",
      "      normal       0.94      0.24      0.39       181\n",
      "       troll       0.08      0.75      0.15         8\n",
      "\n",
      "    accuracy                           0.28       200\n",
      "   macro avg       0.36      0.48      0.21       200\n",
      "weighted avg       0.85      0.28      0.36       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63a70a",
   "metadata": {},
   "source": [
    "# Word2vec + SMOTE + Standardized Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d87ec2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.775\n",
      "F1 Score (Micro): 0.775\n",
      "F1 Score (Macro): 0.44004121423476267\n",
      "ROC AUC (OvO): 0.6904555357813633\n",
      "ROC AUC (OvR): 0.6904555357813633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.19      0.45      0.27        11\n",
      "      normal       0.93      0.82      0.87       181\n",
      "       troll       0.14      0.25      0.18         8\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.42      0.51      0.44       200\n",
      "weighted avg       0.85      0.78      0.81       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.25\n",
      "F1 Score (Micro): 0.25\n",
      "F1 Score (Macro): 0.2155307994757536\n",
      "ROC AUC (OvO): 0.6245253183651656\n",
      "ROC AUC (OvR): 0.6245253183651656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.55      0.11        11\n",
      "      normal       1.00      0.20      0.34       181\n",
      "       troll       0.11      0.88      0.20         8\n",
      "\n",
      "    accuracy                           0.25       200\n",
      "   macro avg       0.39      0.54      0.22       200\n",
      "weighted avg       0.91      0.25      0.32       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.74\n",
      "F1 Score (Micro): 0.74\n",
      "F1 Score (Macro): 0.4467257033746395\n",
      "ROC AUC (OvO): 0.7253627195446145\n",
      "ROC AUC (OvR): 0.7253627195446145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.21      0.55      0.31        11\n",
      "      normal       0.94      0.77      0.84       181\n",
      "       troll       0.12      0.38      0.19         8\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.43      0.56      0.45       200\n",
      "weighted avg       0.87      0.74      0.79       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.265\n",
      "F1 Score (Micro): 0.265\n",
      "F1 Score (Macro): 0.21918162953816603\n",
      "ROC AUC (OvO): 0.6513717399412354\n",
      "ROC AUC (OvR): 0.6513717399412354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.03      0.27      0.05        11\n",
      "      normal       0.91      0.24      0.38       181\n",
      "       troll       0.13      0.88      0.23         8\n",
      "\n",
      "    accuracy                           0.27       200\n",
      "   macro avg       0.36      0.46      0.22       200\n",
      "weighted avg       0.83      0.27      0.35       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Выделение последних четырех признаков для стандартизации\n",
    "X_additional = X[:, -4:]\n",
    "\n",
    "# Стандартизация последних четырех признаков\n",
    "scaler = StandardScaler()\n",
    "X_additional_scaled = scaler.fit_transform(X_additional)\n",
    "\n",
    "# Объединение стандартизированных признаков с остальными\n",
    "X_combined = np.hstack((X[:, :-4], X_additional_scaled))\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d7be4",
   "metadata": {},
   "source": [
    "# PCA (Word2vec) + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21498af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.865\n",
      "F1 Score (Micro): 0.865\n",
      "F1 Score (Macro): 0.5404007756948933\n",
      "ROC AUC (OvO): 0.8290817200955655\n",
      "ROC AUC (OvR): 0.8290817200955655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.40      0.55      0.46        11\n",
      "      normal       0.94      0.91      0.92       181\n",
      "       troll       0.22      0.25      0.24         8\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.52      0.57      0.54       200\n",
      "weighted avg       0.88      0.86      0.87       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.29\n",
      "F1 Score (Micro): 0.29\n",
      "F1 Score (Macro): 0.23942284294707203\n",
      "ROC AUC (OvO): 0.6525923527472473\n",
      "ROC AUC (OvR): 0.6525923527472473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.08      0.64      0.14        11\n",
      "      normal       0.96      0.24      0.39       181\n",
      "       troll       0.11      0.88      0.19         8\n",
      "\n",
      "    accuracy                           0.29       200\n",
      "   macro avg       0.38      0.58      0.24       200\n",
      "weighted avg       0.87      0.29      0.37       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.81\n",
      "F1 Score (Micro): 0.81\n",
      "F1 Score (Macro): 0.5358974358974359\n",
      "ROC AUC (OvO): 0.8503245989445194\n",
      "ROC AUC (OvR): 0.8503245989445194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.30      0.64      0.41        11\n",
      "      normal       0.95      0.83      0.89       181\n",
      "       troll       0.22      0.50      0.31         8\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.49      0.66      0.54       200\n",
      "weighted avg       0.89      0.81      0.84       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.37\n",
      "F1 Score (Micro): 0.37\n",
      "F1 Score (Macro): 0.2389877864608602\n",
      "ROC AUC (OvO): 0.5962456855374038\n",
      "ROC AUC (OvR): 0.5962456855374038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.03      0.18      0.06        11\n",
      "      normal       0.91      0.37      0.53       181\n",
      "       troll       0.08      0.62      0.14         8\n",
      "\n",
      "    accuracy                           0.37       200\n",
      "   macro avg       0.34      0.39      0.24       200\n",
      "weighted avg       0.82      0.37      0.48       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Применение PCA для уменьшения размерности векторов Word2Vec\n",
    "pca = PCA(n_components=25, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42, kernel='rbf')\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8d53727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA (Standardized Word2vec) + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce36387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd753adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df_fin['Vector_features'][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb7f6e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       1000 non-null   object \n",
      " 1   author_name      999 non-null    object \n",
      " 2   text             1000 non-null   object \n",
      " 3   reply_count      1000 non-null   float64\n",
      " 4   top_level        1000 non-null   object \n",
      " 5   index            1000 non-null   object \n",
      " 6   publishedAt      1000 non-null   object \n",
      " 7   updateAt         1000 non-null   object \n",
      " 8   likeCount        1000 non-null   float64\n",
      " 9   Video_ID         1000 non-null   int64  \n",
      " 10  Label            1000 non-null   object \n",
      " 11  Text             1000 non-null   object \n",
      " 12  Processed_Text   1000 non-null   object \n",
      " 13  Vector           1000 non-null   object \n",
      " 14  Vector_features  1000 non-null   object \n",
      " 15  Foreign_Words    1000 non-null   int64  \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 125.1+ KB\n"
     ]
    }
   ],
   "source": [
    "comments_df_fin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5aebcd",
   "metadata": {},
   "source": [
    "# PCA (Word2vec) + SMOTE + Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0c46a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b238ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.865\n",
      "F1 Score (Micro): 0.865\n",
      "F1 Score (Macro): 0.5141460483915014\n",
      "ROC AUC (OvO): 0.731568425419158\n",
      "ROC AUC (OvR): 0.731568425419158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.46      0.55      0.50        11\n",
      "      normal       0.93      0.92      0.92       181\n",
      "       troll       0.11      0.12      0.12         8\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.50      0.53      0.51       200\n",
      "weighted avg       0.87      0.86      0.87       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.175\n",
      "F1 Score (Micro): 0.175\n",
      "F1 Score (Macro): 0.1729593455008298\n",
      "ROC AUC (OvO): 0.5439872590738956\n",
      "ROC AUC (OvR): 0.5439872590738956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.05      0.55      0.09        11\n",
      "      normal       0.96      0.13      0.22       181\n",
      "       troll       0.12      0.75      0.21         8\n",
      "\n",
      "    accuracy                           0.17       200\n",
      "   macro avg       0.38      0.47      0.17       200\n",
      "weighted avg       0.87      0.17      0.22       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.76\n",
      "F1 Score (Micro): 0.76\n",
      "F1 Score (Macro): 0.3952270854925723\n",
      "ROC AUC (OvO): 0.7050505437323009\n",
      "ROC AUC (OvR): 0.7050505437323009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.23      0.55      0.32        11\n",
      "      normal       0.92      0.81      0.86       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.38      0.45      0.40       200\n",
      "weighted avg       0.85      0.76      0.80       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.27\n",
      "F1 Score (Micro): 0.27\n",
      "F1 Score (Macro): 0.21189947529090727\n",
      "ROC AUC (OvO): 0.6244543499271739\n",
      "ROC AUC (OvR): 0.6244543499271739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.45      0.11        11\n",
      "      normal       0.93      0.24      0.38       181\n",
      "       troll       0.08      0.75      0.15         8\n",
      "\n",
      "    accuracy                           0.27       200\n",
      "   macro avg       0.36      0.48      0.21       200\n",
      "weighted avg       0.85      0.27      0.35       200\n",
      "\n",
      "\n",
      "Random Forest Feature Importance:\n",
      "Feature 9: 0.06317844498844191\n",
      "Feature 25: 0.05592465497498208\n",
      "Feature 5: 0.05331966822029702\n",
      "Feature 20: 0.05222209481221346\n",
      "Feature 24: 0.051515392478621524\n",
      "Feature 10: 0.05116724809244415\n",
      "Feature 2: 0.04775105088533455\n",
      "Feature 11: 0.046150465447479826\n",
      "Feature 7: 0.04186249346634308\n",
      "Feature 21: 0.04068710863378556\n",
      "Feature 14: 0.03898609106260458\n",
      "Feature 12: 0.03774634861253877\n",
      "Feature 1: 0.03590953486842488\n",
      "Feature 4: 0.03575275747665388\n",
      "Feature 13: 0.032056656520770624\n",
      "Feature 0: 0.03202194827427323\n",
      "Feature 19: 0.03194471836800137\n",
      "Feature 6: 0.030145352763201592\n",
      "Feature 8: 0.030033325725087635\n",
      "Feature 3: 0.0298650244371977\n",
      "Feature 22: 0.029424739829467916\n",
      "Feature 15: 0.029045785660559313\n",
      "Feature 16: 0.02870142136144419\n",
      "Feature 17: 0.027394160380878173\n",
      "Feature 23: 0.024015798446987136\n",
      "Feature 18: 0.023177714211965895\n",
      "Feature 27: 0.0\n",
      "Feature 26: 0.0\n",
      "Feature 28: 0.0\n",
      "\n",
      "Logistic Regression Feature Importance:\n",
      "Feature 2: 0.006551546094407725\n",
      "Feature 4: 0.004612867956822368\n",
      "Feature 5: 0.004230421967803408\n",
      "Feature 25: 0.003968739891481377\n",
      "Feature 10: 0.003808167197037019\n",
      "Feature 1: 0.003325272820266605\n",
      "Feature 8: 0.0031605505314254148\n",
      "Feature 12: 0.003111858566466612\n",
      "Feature 7: 0.0030587754476940738\n",
      "Feature 9: 0.0022376554803594344\n",
      "Feature 6: 0.002089623892803743\n",
      "Feature 21: 0.0020851842810122316\n",
      "Feature 11: 0.0019624298369542137\n",
      "Feature 0: 0.0019172533092951588\n",
      "Feature 15: 0.0016610460015675274\n",
      "Feature 19: 0.0015925438859855313\n",
      "Feature 23: 0.0015618380508677044\n",
      "Feature 13: 0.001522381516593671\n",
      "Feature 24: 0.0013189891626701764\n",
      "Feature 18: 0.0010459812828830554\n",
      "Feature 3: 0.0008516895495055196\n",
      "Feature 20: 0.0008384235726518568\n",
      "Feature 16: 0.0007245129496058166\n",
      "Feature 22: 0.0003008343662685801\n",
      "Feature 14: 0.00021914885179743967\n",
      "Feature 17: 0.0002017077858717706\n",
      "Feature 27: 0.0\n",
      "Feature 26: 0.0\n",
      "Feature 28: 0.0\n",
      "\n",
      "Gradient Boosting Feature Importance:\n",
      "Feature 25: 0.10393044965132672\n",
      "Feature 9: 0.09408367748825838\n",
      "Feature 24: 0.07594189860817745\n",
      "Feature 20: 0.06578175914201423\n",
      "Feature 7: 0.062418034185719805\n",
      "Feature 5: 0.05769111451686737\n",
      "Feature 10: 0.05659655384945698\n",
      "Feature 12: 0.04884114066608708\n",
      "Feature 2: 0.04825436372867651\n",
      "Feature 11: 0.04158640704169294\n",
      "Feature 21: 0.03758455808109748\n",
      "Feature 14: 0.034521745433823914\n",
      "Feature 0: 0.0306226293097541\n",
      "Feature 6: 0.02943222872819858\n",
      "Feature 4: 0.029352522160260137\n",
      "Feature 1: 0.029291428404599598\n",
      "Feature 13: 0.027853556758315714\n",
      "Feature 19: 0.02444957326886037\n",
      "Feature 22: 0.02410362397667114\n",
      "Feature 15: 0.015595284108712687\n",
      "Feature 17: 0.014549492838176224\n",
      "Feature 3: 0.012906367342168544\n",
      "Feature 8: 0.011193480269419988\n",
      "Feature 16: 0.008916084607587\n",
      "Feature 23: 0.008242743267007604\n",
      "Feature 18: 0.006259282567069403\n",
      "Feature 27: 0.0\n",
      "Feature 26: 0.0\n",
      "Feature 28: 0.0\n",
      "\n",
      "SVC Feature Importance:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Выделение последних четырех признаков для стандартизации\n",
    "X_additional = X[:, -4:]\n",
    "\n",
    "# Применение PCA для уменьшения размерности векторов Word2Vec\n",
    "pca = PCA(n_components=25, random_state=42)\n",
    "X_pca = pca.fit_transform(X[:, :-4])\n",
    "\n",
    "# Стандартизация последних четырех признаков\n",
    "#scaler = StandardScaler()\n",
    "#X_additional_scaled = scaler.fit_transform(X_additional)\n",
    "\n",
    "# Объединение стандартизированных признаков с остальными\n",
    "X_combined = np.hstack((X_pca, X_additional))\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)\n",
    "    \n",
    "# Оценка значимости признаков\n",
    "def feature_importance(model, model_name, X_train, y_train):\n",
    "    print(f\"{model_name} Feature Importance:\")\n",
    "    if model_name == \"Random Forest\" or model_name == \"Gradient Boosting\":\n",
    "        importances = model.feature_importances_\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "        for idx in sorted_indices:\n",
    "            print(f\"Feature {idx}: {importances[idx]}\")\n",
    "    elif model_name == \"Logistic Regression\":\n",
    "        importances = np.abs(model.coef_[0])\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "        for idx in sorted_indices:\n",
    "            print(f\"Feature {idx}: {importances[idx]}\")\n",
    "    elif model_name == \"SVC\":\n",
    "        if hasattr(model, \"coef_\"):\n",
    "            importances = np.abs(model.coef_[0])\n",
    "            sorted_indices = np.argsort(importances)[::-1]\n",
    "            for idx in sorted_indices:\n",
    "                print(f\"Feature {idx}: {importances[idx]}\")\n",
    "        else:\n",
    "            result = permutation_importance(model, X_train, y_train, n_repeats=10, random_state=42, n_jobs=2)\n",
    "            sorted_indices = result.importances_mean.argsort()[::-1]\n",
    "            for idx in sorted_indices:\n",
    "                print(f\"Feature {idx}: {result.importances_mean[idx]}\")\n",
    "    print()\n",
    "\n",
    "# Вывод значимости признаков для каждой модели\n",
    "for name, model in models.items():\n",
    "    feature_importance(model, name, X_train_smote, y_train_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d5bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
