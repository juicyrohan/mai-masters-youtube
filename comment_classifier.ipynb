{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b1b115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "#from gensim.models import Word2Vec \n",
    "from itertools import combinations \n",
    "import random \n",
    "import pandas as pd \n",
    "from sklearn.calibration import label_binarize \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, f1_score, roc_auc_score \n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "import numpy as np \n",
    "from transformers import BertTokenizer, BertModel \n",
    "#import shap \n",
    "import matplotlib.pyplot as plt \n",
    "from imblearn.over_sampling import SMOTE \n",
    "import seaborn as sns \n",
    "from ast import literal_eval\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from langdetect import detect\n",
    "import pickle\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from spacy.lang.ru.stop_words import STOP_WORDS as stop_words\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41dbe5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv('comments_f2v_fts.csv')\n",
    "videos_df = pd.read_csv('vid_fin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a58e7b",
   "metadata": {},
   "source": [
    "Отбиарем 1000 размеченных комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21847835",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = comments_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8181b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для подсчета иностранных слов\n",
    "def count_foreign_words(text):\n",
    "    if isinstance(text, str):\n",
    "        foreign_word_count = 0\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            try:\n",
    "                lang = detect(word)\n",
    "                if lang != 'ru':\n",
    "                    foreign_word_count += 1\n",
    "            except LangDetectException:\n",
    "                continue  # Пропускаем слово, если не удалось определить язык\n",
    "        return foreign_word_count\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e2d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['Foreign_Words'] = comments_df['Processed_Text'].apply(count_foreign_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c31f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели spaCy для русского языка\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "comments_df['Text'] = comments_df['Text'].fillna('').astype(str)\n",
    "# Функция для предобработки текста\n",
    "def preprocess_text(text):\n",
    "    # Обработка NaN значений\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Удаление ссылок и других ненужных символов\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@w+|\\#', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Токенизация и лемматизация\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.lemma_ not in stop_words and token.is_alpha]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Применение предобработки к каждому тексту\n",
    "comments_df['Processed_Text'] = comments_df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Создание корпуса из текстов комментариев\n",
    "corpus = comments_df['Processed_Text'].tolist()\n",
    "\n",
    "# Разделение текста на предложения\n",
    "sentences = [text.split() for text in corpus]\n",
    "\n",
    "# Создание модели Word2Vec\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_comment_vector(comment, model):\n",
    "    words = comment.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "    \n",
    "def extract_additional_features(comment):\n",
    "    length = len(comment)\n",
    "    uppercase_count = sum(1 for c in comment if c.isupper())\n",
    "    punctuation_count = sum(1 for c in comment if c in string.punctuation)\n",
    "    emoji_count = len(re.findall(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0]+', comment))\n",
    "    return np.array([length, uppercase_count, punctuation_count, emoji_count])\n",
    "\n",
    "# Преобразование всех комментариев в векторы и добавление дополнительных признаков\n",
    "def get_combined_vector(comment, model):\n",
    "    word_vector = get_comment_vector(comment, model)\n",
    "    additional_features = extract_additional_features(comment)\n",
    "    combined_vector = np.concatenate((word_vector, additional_features), axis=None)\n",
    "    return combined_vector\n",
    "\n",
    "# Преобразование всех комментариев в векторы\n",
    "comments_df['Vector'] = comments_df['Processed_Text'].apply(lambda x: get_comment_vector(x, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6c1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df['Vector_features'] = comments_df['Text'].apply(lambda x: get_combined_vector(preprocess_text(x), word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79280d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_features_label = pd.read_csv('vid_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cbafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df_fin = comments_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef655cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df_fin['Label'] = comm_features_label['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7dc0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = ['LDA_Similarity', 'Thread_Similarity', 'Videosub_Similarity', 'Sentiment_Label', 'Sentiment_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d44af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df_fin[new_features] = comm_features_label[new_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e730b66",
   "metadata": {},
   "source": [
    "Теперь построим модель классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0eea31",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2dd668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.4269255603687511\n",
      "ROC AUC (OvR): 0.4269255603687511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.905\n",
      "F1 Score (Micro): 0.905\n",
      "F1 Score (Macro): 0.31671041119860016\n",
      "ROC AUC (OvO): 0.6244456579965479\n",
      "ROC AUC (OvR): 0.6244456579965479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.00      0.00      0.00        11\n",
      "      normal       0.91      1.00      0.95       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.30      0.33      0.32       200\n",
      "weighted avg       0.82      0.91      0.86       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.5455621705396426\n",
      "ROC AUC (OvR): 0.5455621705396426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.5445465355559511\n",
      "ROC AUC (OvR): 0.5445465355559511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.4269255603687511\n",
      "ROC AUC (OvR): 0.4269255603687511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.905\n",
      "F1 Score (Micro): 0.905\n",
      "F1 Score (Macro): 0.31671041119860016\n",
      "ROC AUC (OvO): 0.6244456579965479\n",
      "ROC AUC (OvR): 0.6244456579965479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.00      0.00      0.00        11\n",
      "      normal       0.91      1.00      0.95       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.30      0.33      0.32       200\n",
      "weighted avg       0.82      0.91      0.86       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.5455621705396426\n",
      "ROC AUC (OvR): 0.5455621705396426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "Accuracy: 0.92\n",
      "F1 Score (Micro): 0.92\n",
      "F1 Score (Macro): 0.46208112874779544\n",
      "ROC AUC (OvO): 0.5445465355559511\n",
      "ROC AUC (OvR): 0.5445465355559511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.27      0.43        11\n",
      "      normal       0.92      1.00      0.96       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.64      0.42      0.46       200\n",
      "weighted avg       0.89      0.92      0.89       200\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)\n",
    "    \n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab84075",
   "metadata": {},
   "source": [
    "# Word2vec + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4586c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.89\n",
      "F1 Score (Micro): 0.89\n",
      "F1 Score (Macro): 0.472135955831608\n",
      "ROC AUC (OvO): 0.6221793962111445\n",
      "ROC AUC (OvR): 0.6221793962111445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.50      0.45      0.48        11\n",
      "      normal       0.93      0.96      0.94       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.48      0.47      0.47       200\n",
      "weighted avg       0.86      0.89      0.88       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.415\n",
      "F1 Score (Micro): 0.415\n",
      "F1 Score (Macro): 0.27315172018121747\n",
      "ROC AUC (OvO): 0.5743278209173773\n",
      "ROC AUC (OvR): 0.5743278209173773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.08      0.55      0.14        11\n",
      "      normal       0.95      0.41      0.57       181\n",
      "       troll       0.06      0.38      0.10         8\n",
      "\n",
      "    accuracy                           0.41       200\n",
      "   macro avg       0.36      0.44      0.27       200\n",
      "weighted avg       0.87      0.41      0.53       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.865\n",
      "F1 Score (Micro): 0.865\n",
      "F1 Score (Macro): 0.46090741670852164\n",
      "ROC AUC (OvO): 0.6230036383499721\n",
      "ROC AUC (OvR): 0.6230036383499721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.45      0.45      0.45        11\n",
      "      normal       0.93      0.93      0.93       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.46      0.46      0.46       200\n",
      "weighted avg       0.86      0.86      0.86       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.825\n",
      "F1 Score (Micro): 0.825\n",
      "F1 Score (Macro): 0.43532763532763535\n",
      "ROC AUC (OvO): 0.7140574294976995\n",
      "ROC AUC (OvR): 0.7140574294976995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.32      0.55      0.40        11\n",
      "      normal       0.94      0.88      0.91       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.42      0.47      0.44       200\n",
      "weighted avg       0.86      0.82      0.84       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ed883",
   "metadata": {},
   "source": [
    "# Standardized Word2vec + SMOTE + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf25a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/00/4_gxgzyx7131tsyx_ymz0hsm0000gn/T/ipykernel_6970/515049937.py\", line 12, in <module>\n",
      "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/imblearn/base.py\", line 203, in fit_resample\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/imblearn/base.py\", line 88, in fit_resample\n",
      "    X : {array-like, dataframe, sparse matrix} of shape \\\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py\", line 355, in _fit_resample\n",
      "    random_state=random_state,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py\", line 824, in kneighbors\n",
      "    else:\n",
      "          \n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 277, in compute\n",
      "    if X.dtype == Y.dtype == np.float64:\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 95, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 135, in threadpool_limits\n",
      "    the_min = the_min.toarray().ravel()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 129, in _get_threadpool_controller\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 818, in __init__\n",
      "    self._load_libraries()\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 970, in _load_libraries\n",
      "    self._find_libraries_with_dyld()\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 1040, in _find_libraries_with_dyld\n",
      "    self._make_controller_from_path(filepath)\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 1175, in _make_controller_from_path\n",
      "    lib_controller = controller_class(\n",
      "                     ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/threadpoolctl.py\", line 114, in __init__\n",
      "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: image not already loaded\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Стандартизация признаков\n",
    "scaler = StandardScaler()\n",
    "X_train_smote = scaler.fit_transform(X_train_smote)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025189b",
   "metadata": {},
   "source": [
    "# Word2vec + SMOTE + Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b37886de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.64\n",
      "F1 Score (Micro): 0.64\n",
      "F1 Score (Macro): 0.36143237605691514\n",
      "ROC AUC (OvO): 0.686852599321098\n",
      "ROC AUC (OvR): 0.686852599321098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.14      0.45      0.21        11\n",
      "      normal       0.91      0.67      0.77       181\n",
      "       troll       0.07      0.25      0.11         8\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.37      0.46      0.36       200\n",
      "weighted avg       0.83      0.64      0.71       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.26\n",
      "F1 Score (Micro): 0.26\n",
      "F1 Score (Macro): 0.22210820446114565\n",
      "ROC AUC (OvO): 0.6332451479631573\n",
      "ROC AUC (OvR): 0.6332451479631573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.55      0.11        11\n",
      "      normal       0.95      0.22      0.35       181\n",
      "       troll       0.12      0.88      0.21         8\n",
      "\n",
      "    accuracy                           0.26       200\n",
      "   macro avg       0.38      0.55      0.22       200\n",
      "weighted avg       0.87      0.26      0.33       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.71\n",
      "F1 Score (Micro): 0.7100000000000001\n",
      "F1 Score (Macro): 0.4545147588662551\n",
      "ROC AUC (OvO): 0.727754744698866\n",
      "ROC AUC (OvR): 0.727754744698866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.19      0.55      0.28        11\n",
      "      normal       0.95      0.72      0.82       181\n",
      "       troll       0.17      0.62      0.26         8\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.43      0.63      0.45       200\n",
      "weighted avg       0.88      0.71      0.77       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.275\n",
      "F1 Score (Micro): 0.275\n",
      "F1 Score (Macro): 0.21466772343965324\n",
      "ROC AUC (OvO): 0.6278132876662609\n",
      "ROC AUC (OvR): 0.6278132876662609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.45      0.11        11\n",
      "      normal       0.94      0.24      0.39       181\n",
      "       troll       0.08      0.75      0.15         8\n",
      "\n",
      "    accuracy                           0.28       200\n",
      "   macro avg       0.36      0.48      0.21       200\n",
      "weighted avg       0.85      0.28      0.36       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63a70a",
   "metadata": {},
   "source": [
    "# Word2vec + SMOTE + Standardized Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d87ec2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.775\n",
      "F1 Score (Micro): 0.775\n",
      "F1 Score (Macro): 0.44004121423476267\n",
      "ROC AUC (OvO): 0.6904555357813633\n",
      "ROC AUC (OvR): 0.6904555357813633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.19      0.45      0.27        11\n",
      "      normal       0.93      0.82      0.87       181\n",
      "       troll       0.14      0.25      0.18         8\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.42      0.51      0.44       200\n",
      "weighted avg       0.85      0.78      0.81       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.25\n",
      "F1 Score (Micro): 0.25\n",
      "F1 Score (Macro): 0.2155307994757536\n",
      "ROC AUC (OvO): 0.6245253183651656\n",
      "ROC AUC (OvR): 0.6245253183651656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.06      0.55      0.11        11\n",
      "      normal       1.00      0.20      0.34       181\n",
      "       troll       0.11      0.88      0.20         8\n",
      "\n",
      "    accuracy                           0.25       200\n",
      "   macro avg       0.39      0.54      0.22       200\n",
      "weighted avg       0.91      0.25      0.32       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.74\n",
      "F1 Score (Micro): 0.74\n",
      "F1 Score (Macro): 0.4467257033746395\n",
      "ROC AUC (OvO): 0.7253627195446145\n",
      "ROC AUC (OvR): 0.7253627195446145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.21      0.55      0.31        11\n",
      "      normal       0.94      0.77      0.84       181\n",
      "       troll       0.12      0.38      0.19         8\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.43      0.56      0.45       200\n",
      "weighted avg       0.87      0.74      0.79       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.265\n",
      "F1 Score (Micro): 0.265\n",
      "F1 Score (Macro): 0.21918162953816603\n",
      "ROC AUC (OvO): 0.6513717399412354\n",
      "ROC AUC (OvR): 0.6513717399412354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.03      0.27      0.05        11\n",
      "      normal       0.91      0.24      0.38       181\n",
      "       troll       0.13      0.88      0.23         8\n",
      "\n",
      "    accuracy                           0.27       200\n",
      "   macro avg       0.36      0.46      0.22       200\n",
      "weighted avg       0.83      0.27      0.35       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Выделение последних четырех признаков для стандартизации\n",
    "X_additional = X[:, -4:]\n",
    "\n",
    "# Стандартизация последних четырех признаков\n",
    "scaler = StandardScaler()\n",
    "X_additional_scaled = scaler.fit_transform(X_additional)\n",
    "\n",
    "# Объединение стандартизированных признаков с остальными\n",
    "X_combined = np.hstack((X[:, :-4], X_additional_scaled))\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d7be4",
   "metadata": {},
   "source": [
    "# PCA (Word2vec) + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21498af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.865\n",
      "F1 Score (Micro): 0.865\n",
      "F1 Score (Macro): 0.5404007756948933\n",
      "ROC AUC (OvO): 0.8290817200955655\n",
      "ROC AUC (OvR): 0.8290817200955655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.40      0.55      0.46        11\n",
      "      normal       0.94      0.91      0.92       181\n",
      "       troll       0.22      0.25      0.24         8\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.52      0.57      0.54       200\n",
      "weighted avg       0.88      0.86      0.87       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.29\n",
      "F1 Score (Micro): 0.29\n",
      "F1 Score (Macro): 0.23942284294707203\n",
      "ROC AUC (OvO): 0.6525923527472473\n",
      "ROC AUC (OvR): 0.6525923527472473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.08      0.64      0.14        11\n",
      "      normal       0.96      0.24      0.39       181\n",
      "       troll       0.11      0.88      0.19         8\n",
      "\n",
      "    accuracy                           0.29       200\n",
      "   macro avg       0.38      0.58      0.24       200\n",
      "weighted avg       0.87      0.29      0.37       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.81\n",
      "F1 Score (Micro): 0.81\n",
      "F1 Score (Macro): 0.5358974358974359\n",
      "ROC AUC (OvO): 0.8503245989445194\n",
      "ROC AUC (OvR): 0.8503245989445194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.30      0.64      0.41        11\n",
      "      normal       0.95      0.83      0.89       181\n",
      "       troll       0.22      0.50      0.31         8\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.49      0.66      0.54       200\n",
      "weighted avg       0.89      0.81      0.84       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.37\n",
      "F1 Score (Micro): 0.37\n",
      "F1 Score (Macro): 0.2389877864608602\n",
      "ROC AUC (OvO): 0.5962456855374038\n",
      "ROC AUC (OvR): 0.5962456855374038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.03      0.18      0.06        11\n",
      "      normal       0.91      0.37      0.53       181\n",
      "       troll       0.08      0.62      0.14         8\n",
      "\n",
      "    accuracy                           0.37       200\n",
      "   macro avg       0.34      0.39      0.24       200\n",
      "weighted avg       0.82      0.37      0.48       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Применение PCA для уменьшения размерности векторов Word2Vec\n",
    "pca = PCA(n_components=25, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42, kernel='rbf')\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8d53727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA (Standardized Word2vec) + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce36387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd753adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df_fin['Vector_features'][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20589572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       1000 non-null   object \n",
      " 1   author_name      999 non-null    object \n",
      " 2   text             1000 non-null   object \n",
      " 3   reply_count      1000 non-null   float64\n",
      " 4   top_level        1000 non-null   object \n",
      " 5   index            1000 non-null   object \n",
      " 6   publishedAt      1000 non-null   object \n",
      " 7   updateAt         1000 non-null   object \n",
      " 8   likeCount        1000 non-null   float64\n",
      " 9   Video_ID         1000 non-null   int64  \n",
      " 10  Label            1000 non-null   object \n",
      " 11  Text             1000 non-null   object \n",
      " 12  Processed_Text   1000 non-null   object \n",
      " 13  Vector           1000 non-null   object \n",
      " 14  Vector_features  1000 non-null   object \n",
      " 15  Foreign_Words    1000 non-null   int64  \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 125.1+ KB\n"
     ]
    }
   ],
   "source": [
    "comments_df_fin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5aebcd",
   "metadata": {},
   "source": [
    "# PCA (Word2vec) + SMOTE + Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0c46a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b238ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratappokkharel/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.91\n",
      "F1 Score (Micro): 0.91\n",
      "F1 Score (Macro): 0.517117117117117\n",
      "ROC AUC (OvO): 0.7234060109694491\n",
      "ROC AUC (OvR): 0.7234060109694491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.67      0.55      0.60        11\n",
      "      normal       0.93      0.97      0.95       181\n",
      "       troll       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.53      0.51      0.52       200\n",
      "weighted avg       0.88      0.91      0.89       200\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.235\n",
      "F1 Score (Micro): 0.235\n",
      "F1 Score (Macro): 0.19554274671071115\n",
      "ROC AUC (OvO): 0.6666071567090138\n",
      "ROC AUC (OvR): 0.6666071567090138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.09      0.64      0.16        11\n",
      "      normal       0.90      0.19      0.32       181\n",
      "       troll       0.06      0.62      0.11         8\n",
      "\n",
      "    accuracy                           0.23       200\n",
      "   macro avg       0.35      0.48      0.20       200\n",
      "weighted avg       0.82      0.23      0.30       200\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.84\n",
      "F1 Score (Micro): 0.8399999999999999\n",
      "F1 Score (Macro): 0.48643737403773085\n",
      "ROC AUC (OvO): 0.6969591162965871\n",
      "ROC AUC (OvR): 0.6969591162965871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.38      0.55      0.44        11\n",
      "      normal       0.93      0.89      0.91       181\n",
      "       troll       0.09      0.12      0.11         8\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.47      0.52      0.49       200\n",
      "weighted avg       0.87      0.84      0.85       200\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.275\n",
      "F1 Score (Micro): 0.275\n",
      "F1 Score (Macro): 0.20455512984248617\n",
      "ROC AUC (OvO): 0.6312721348016553\n",
      "ROC AUC (OvR): 0.6312721348016553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.04      0.27      0.07        11\n",
      "      normal       0.90      0.25      0.40       181\n",
      "       troll       0.08      0.75      0.15         8\n",
      "\n",
      "    accuracy                           0.28       200\n",
      "   macro avg       0.34      0.43      0.20       200\n",
      "weighted avg       0.82      0.28      0.37       200\n",
      "\n",
      "\n",
      "Random Forest Feature Importance:\n",
      "Feature 33: 0.07539583084073732\n",
      "Feature 32: 0.07419317885137795\n",
      "Feature 29: 0.048973124358814075\n",
      "Feature 9: 0.04444768826800431\n",
      "Feature 25: 0.0421456811695951\n",
      "Feature 10: 0.03869968779200432\n",
      "Feature 2: 0.037161781388686754\n",
      "Feature 24: 0.03627430772208256\n",
      "Feature 5: 0.03505452276768611\n",
      "Feature 31: 0.034670038929633926\n",
      "Feature 30: 0.034095019145102747\n",
      "Feature 20: 0.03267139042722605\n",
      "Feature 7: 0.032390329916877694\n",
      "Feature 21: 0.029882454189439422\n",
      "Feature 13: 0.02985092942286833\n",
      "Feature 11: 0.02932146225698696\n",
      "Feature 22: 0.029019336408678976\n",
      "Feature 19: 0.028072302428662915\n",
      "Feature 12: 0.027465815040693096\n",
      "Feature 4: 0.026589500245706603\n",
      "Feature 1: 0.02566556493862995\n",
      "Feature 14: 0.02515713058893266\n",
      "Feature 0: 0.024929941873535824\n",
      "Feature 8: 0.021290687565658283\n",
      "Feature 23: 0.02089630633441283\n",
      "Feature 16: 0.020862919249682327\n",
      "Feature 6: 0.020305517635101227\n",
      "Feature 17: 0.02010370346351961\n",
      "Feature 3: 0.019215948565082217\n",
      "Feature 15: 0.019047230333965142\n",
      "Feature 18: 0.016150667880614856\n",
      "Feature 26: 0.0\n",
      "Feature 27: 0.0\n",
      "Feature 28: 0.0\n",
      "\n",
      "Logistic Regression Feature Importance:\n",
      "Feature 33: 2.8400272855501028\n",
      "Feature 31: 2.1533086126328027\n",
      "Feature 29: 2.0264996112198137\n",
      "Feature 30: 0.8916702937301714\n",
      "Feature 2: 0.5167134895704781\n",
      "Feature 32: 0.5071347371116904\n",
      "Feature 10: 0.3187086847048474\n",
      "Feature 4: 0.30221159611482357\n",
      "Feature 6: 0.24529601855144167\n",
      "Feature 7: 0.22326560440232818\n",
      "Feature 8: 0.20854482395602938\n",
      "Feature 13: 0.20566882151510651\n",
      "Feature 9: 0.20516851448607035\n",
      "Feature 5: 0.19806482976317588\n",
      "Feature 12: 0.18140728185213403\n",
      "Feature 19: 0.1733436256176392\n",
      "Feature 11: 0.15710876074100252\n",
      "Feature 1: 0.14182995218430167\n",
      "Feature 20: 0.11943817950302105\n",
      "Feature 21: 0.11068592248665693\n",
      "Feature 14: 0.10828646151350677\n",
      "Feature 15: 0.08464767865648685\n",
      "Feature 16: 0.04886442600016866\n",
      "Feature 23: 0.04196415591968339\n",
      "Feature 3: 0.031185863916796994\n",
      "Feature 22: 0.022487937250925023\n",
      "Feature 17: 0.021968383189997484\n",
      "Feature 0: 0.01635972413520845\n",
      "Feature 24: 0.010733768123846816\n",
      "Feature 18: 0.0014402242240273539\n",
      "Feature 25: 0.0013019104704856408\n",
      "Feature 26: 0.0\n",
      "Feature 27: 0.0\n",
      "Feature 28: 0.0\n",
      "\n",
      "Gradient Boosting Feature Importance:\n",
      "Feature 32: 0.2210006808502458\n",
      "Feature 33: 0.0853902896743249\n",
      "Feature 10: 0.061754453292681616\n",
      "Feature 29: 0.05767558988874103\n",
      "Feature 9: 0.054968315291032493\n",
      "Feature 30: 0.0522137561444834\n",
      "Feature 2: 0.04504228780649095\n",
      "Feature 25: 0.035224571457704947\n",
      "Feature 24: 0.032485244019727924\n",
      "Feature 13: 0.029274071900731093\n",
      "Feature 5: 0.028118117668522763\n",
      "Feature 7: 0.027111742765728124\n",
      "Feature 22: 0.02708270473691312\n",
      "Feature 31: 0.026825840411823093\n",
      "Feature 4: 0.02664904169112876\n",
      "Feature 11: 0.02442899281445457\n",
      "Feature 19: 0.021365898325577674\n",
      "Feature 12: 0.02092578895282123\n",
      "Feature 20: 0.019901352263228717\n",
      "Feature 14: 0.01976489466795946\n",
      "Feature 6: 0.015584287600793618\n",
      "Feature 8: 0.012955096547428775\n",
      "Feature 0: 0.012181310488122933\n",
      "Feature 17: 0.01180836579022835\n",
      "Feature 21: 0.01002983008876092\n",
      "Feature 3: 0.00492537786446756\n",
      "Feature 15: 0.004653439164986402\n",
      "Feature 23: 0.0037765108581842358\n",
      "Feature 18: 0.002462178765833713\n",
      "Feature 16: 0.0022530720945077793\n",
      "Feature 1: 0.002166896112364021\n",
      "Feature 26: 0.0\n",
      "Feature 27: 0.0\n",
      "Feature 28: 0.0\n",
      "\n",
      "SVC Feature Importance:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = np.vstack(comments_df_fin['Vector_features'].values)\n",
    "y = comments_df_fin['Label']\n",
    "\n",
    "# Добавление дополнительных признаков 29 - 33\n",
    "additional_features = comments_df_fin[['LDA_Similarity', 'Thread_Similarity', 'Videosub_Similarity',  \n",
    "                                       'Sentiment_Label', 'Sentiment_Score']].values\n",
    "\n",
    "# Выделение последних четырех признаков для стандартизации 25 - 28\n",
    "X_additional = X[:, -4:]\n",
    "\n",
    "# Применение PCA для уменьшения размерности векторов Word2Vec  0 - 24\n",
    "pca = PCA(n_components=25, random_state=42)\n",
    "X_pca = pca.fit_transform(X[:, :-4])\n",
    "\n",
    "# Стандартизация последних четырех признаков\n",
    "#scaler = StandardScaler()\n",
    "#X_additional_scaled = scaler.fit_transform(X_additional)\n",
    "\n",
    "# Объединение стандартизированных признаков с остальными\n",
    "#X_combined = np.hstack((X_pca, X_additional))\n",
    "X_combined = np.hstack((X_pca, X_additional, additional_features))\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение SMOTE к обучающей выборке\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Создание и обучение моделей\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial', solver='lbfgs')\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"SVC\": svc_model,\n",
    "#    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Предсказание на тестовых данных и оценка моделей\n",
    "def evaluate_model(y_test, y_pred, y_proba, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test_binarized = lb.transform(y_test)\n",
    "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_proba, multi_class='ovo')\n",
    "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score (Micro):\", f1_micro)\n",
    "    print(\"F1 Score (Macro):\", f1_macro)\n",
    "    print(\"ROC AUC (OvO):\", roc_auc_ovo)\n",
    "    print(\"ROC AUC (OvR):\", roc_auc_ovr)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Вывод результатов для каждой модели\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        # For models without predict_proba (e.g., SVC without probability=True)\n",
    "        ovo_classifier = OneVsOneClassifier(model)\n",
    "        ovo_classifier.fit(X_train, y_train)\n",
    "        y_proba = ovo_classifier.decision_function(X_test)\n",
    "    evaluate_model(y_test, y_pred, y_proba, name)\n",
    "    \n",
    "# Оценка значимости признаков\n",
    "def feature_importance(model, model_name, X_train, y_train):\n",
    "    print(f\"{model_name} Feature Importance:\")\n",
    "    if model_name == \"Random Forest\" or model_name == \"Gradient Boosting\":\n",
    "        importances = model.feature_importances_\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "        for idx in sorted_indices:\n",
    "            print(f\"Feature {idx}: {importances[idx]}\")\n",
    "    elif model_name == \"Logistic Regression\":\n",
    "        importances = np.abs(model.coef_[0])\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "        for idx in sorted_indices:\n",
    "            print(f\"Feature {idx}: {importances[idx]}\")\n",
    "    elif model_name == \"SVC\":\n",
    "        if hasattr(model, \"coef_\"):\n",
    "            importances = np.abs(model.coef_[0])\n",
    "            sorted_indices = np.argsort(importances)[::-1]\n",
    "            for idx in sorted_indices:\n",
    "                print(f\"Feature {idx}: {importances[idx]}\")\n",
    "        else:\n",
    "            result = permutation_importance(model, X_train, y_train, n_repeats=10, random_state=42, n_jobs=2)\n",
    "            sorted_indices = result.importances_mean.argsort()[::-1]\n",
    "            for idx in sorted_indices:\n",
    "                print(f\"Feature {idx}: {result.importances_mean[idx]}\")\n",
    "    print()\n",
    "\n",
    "# Вывод значимости признаков для каждой модели\n",
    "for name, model in models.items():\n",
    "    feature_importance(model, name, X_train_smote, y_train_smote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b41e48",
   "metadata": {},
   "source": [
    "Выходит, из дополнительных признаков знаичмыми являются только - 'LDA_Similarity', 'Thread_Similarity', 'Videosub_Similarity', 'Sentiment_Label', 'Sentiment_Score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020ec4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86012ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e99e9944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'author_name', 'text', 'reply_count', 'top_level',\n",
       "       'index', 'publishedAt', 'updateAt', 'likeCount', 'Video_ID', 'Label',\n",
       "       'Text', 'Processed_Text', 'Vector', 'Vector_features', 'Foreign_Words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df_fin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74327641",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df_fin[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
